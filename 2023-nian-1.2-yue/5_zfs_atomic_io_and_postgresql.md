# ZFS的 Atomic I/O 和 PostgreSQL
**作者：Thomas Munro**

PostgreSQL 是一个实施 SQL 标准的关系数据库管理系统，具有类似BSD的许可证。其SQL之前的前身 POSTGRES 始于20世纪80年代中期的伯克利大学。它在FreeBSD上很流行，通常部署在ZFS存储上。。

许多关于 PostgreSQL 在 ZFS 上的文章建议改变 ZFS 的 **recordsize** 设置和 PostgreSQL 的 **full_page_writes** 设置。后者的设置对性能和崩溃安全的真正影响并不经常被解释，也许是因为在大多数流行的文件系统上调整它通常是不安全的。在这篇文章中，围绕块的大小讨论之后我总结了这一神秘机制背后的逻辑和权衡。 

## 块
几乎所有 PostgreSQL 的磁盘 I/O 都是在 8KB 块或页面上对齐的。可以重新编译它以使用不同的大小，但很少有人这样做。这个大小最初可能是为了匹配 UFS 的历史默认块大小（不过请注意 FreeBSD 的 UFS 现在默认为32KB）。ZFS 使用术语 "记录大小"，并默认为128KB。与其他文件系统不同，ZFS 允许在任何时候轻松改变记录大小，并为每个数据集单独配置。

如果数据是随机访问，那么在理论上，其大小最好与PostgreSQL的 8KB 的块相匹配。否则，随机 I/O 可能会受到两种影响。

- I/O放大，因为对 8KB 块的每一次读或写都会传输额外的邻近的数据

- 当存储块当前不在操作系统的缓存中并且必须写入8KB的块时，先读后写，因此必须先读取相邻的数据

如果数据将主要按顺序访问，或者很少访问，特别是如果使用较大记录的 ZFS 压缩的好处超过了对 I/O 带宽和延迟的担忧，那么这可能是一个好主意。

一些资料全面推荐16KB、32KB或128KB的记录大小，作为在没有太多写入放大或延迟的情况下实现更好压缩的最佳点。我在这里的目的不是提出这样的建议—我不能肯定有一个答案-而是要解释正在发生的事情。

有些应用程序对不同类型的数据有多种要求。表空间可以用于将不同的表存储在具有不同记录大小、压缩或物理介质的不同ZFS数据集中。也可以对表进行分区，例如，较旧的数据在一个表空间中，当前活动数据在另一个表空间中。

```
CREATE TABLESPACE compressed_tablespace
LOCATION ’/tank/pgdata/compressed_tablespace‘;
ALTER TABLE t
SET TABLESPACE compressed_tablespace;
```

据报告，小的 ZFS 记录的一个问题是碎片。一个频繁接收随机更新的表最终可能会出现分散在各处的块，我们更希望它们在物理上被集中起来，以获得良好的顺序读取性能。如果您准备在重写期间将查询锁定在表之外，那么要求 PostgreSQL 重写包含表及其索引的文件以便在 ZFS 级别对其进行碎片整理的一种简单方法是执行 **VACUUM FULL table_name** 或 **CLUSTER table_name**。如果在数据集级别更改了新的记录大小，则重写表也可以使其生效。

## 被损坏的写入
PostgreSQL 设置 **full_page_writes** 默认为打开，ZFS用户经常将其关闭。这样写密集型工作负载的性能就会变得更快、更一致。例如，在一个低端云虚拟机上的简单 pgbench 测试中，我通过关闭它来测量每秒增加32%的事务。

那么它到底有什么作用呢？这需要大量的背景解释。

简短的版本是 PostgreSQL 使用 *physiological logging* 来确保崩溃安全，这意味着在 *电源故障* 时对单个数据库页面的写入必须是原子的，否则可能在崩溃后无法恢复。除非您承诺您的存储栈具有该属性，否则PostgreSQL必须做一些额外的工作来保护您的数据。

断电原子性是这样一种特性，即如果断电时物理写入正在进行，那么对于某些给定的块大小，稍后我们可以预期读取块的旧版本或新版本，但不能读取部分修改或损坏的版本。不要将其与并发读写的原子性混淆（见下文）。Physiological logging，是 *物理到页面、页面内逻辑* 的缩写，是教科书中记录策略分类的一个术语，它意味着日志记录通过文件和块号识别要更改的块，但随后在注释中描述要在该页面内进行的更改，这需要我们读入现有页面，以了解如何“逻辑”修改它，而不仅仅是更新物理地址的位。

崩溃后，恢复算法可以处理“旧”页面内容或“新”页面内容，应用所需的任何日志更改以使其更新。如果遇到新旧数据的非原子混合，则无法回放对页面的逻辑更改，恢复也将失败！一个表面上的问题是，如果启用了**data_checksums**，那么 PostgreSQL 的页面级校验和检查将失败，甚至无法读取页面。如果禁用了校验和，我们将进一步了解，但诸如“在插槽3中插入元组（42，Fred）”之类的逻辑更改无法可靠地回放。为了在本例中应用更改，我们需要使用页面上预先存在的元数据来理解一个槽的表格，但它可能已损坏。

Physiological logging 是数据库行业中应用非常广泛的技术，不同的 RDBMS 已经找到了不同的解决页面数据被损坏的问题的方法。由于开源系统已经被开发并用于通常没有各种形式的硬件保护来防止电源损失的各种各样的低端系统，因此故障很常见，必须开发软件解决方案。

PostgreSQL目前的解决方案是切换到页面级仅 physical-only logging 或 *full page writes*，将整个数据页转储到日志中，以便在每个检查点之后对每个数据页进行第一次修改。检查点是一种周期性的后台活动，在理想的情况下，对前台事务性能的影响微乎其微。然而，由于首次接触规则，一旦检查点启动，写繁重的工作负载可能会突然开始生成更多的日志数据，因为小的更新突然需要记录许多 8KB 的页面。这种影响通常会逐渐减弱，因为对每个页面的后续修改会回到 physiological，直到下一个检查点，有时会导致 I/O 带宽和事务延迟出现锯齿状。

另一个流行的开源数据库有一个不同的解决方案，它还包括将所有数据写两次，并在两次之间设置同步屏障，因为这两个副本都不能被损坏。

ZFS不需要这些！由于它自己的写时复制设计具有记录级的原子性。不可能看到 ZFS 记录的新旧内容的混合，因为它不会物理覆盖它们，而且它的 TXG 和 ZIL 系统使写入成为事务性的。因此，只要 **recordsize** 至少为8KB，就可以安全地设置 **full_page_writes=off**。

请注意，在某些场景中，ZFS 本身也会物理地写入两次数据。一个常见的建议是考虑为包含主要数据文件的数据集设置 **logbias=throughput**（但也许不是保存PostgreSQL的日志目录pg_wal的那个，这个话题在本文中没有探讨过)。该选项尝试将块直接写入它们的最终位置，而不是首先将它们记录在 ZIL 中。如果您使用 ZFS 默认的 **logbias=latency** 和 PostgreSQL 默认的 **full_page_writes=on**，那么实际上数据可能总共被写了四次，因为 PostgreSQL 和 ZFS 都需要执行额外的工作来创建记录级的一致性，而这两个更改都会将其减少到一个副本。

不幸的是，在两种特殊情况下，仍然需要 f**ull_page_writes=on** 才能进行正确的行为：在运行 **pg_basebackup** 和 **pg_rewind** 时。这些工具用于备份，或从另一个服务器创建或重新同步流复制副本；在 **pg_basebackup** 的情况下，在运行该命令时将以静默方式启用全页写入，而在 **pg_rewind** 的情况下，如果未手动启用该命令，则该命令将拒绝运行（当前版本中存在令人讨厌的不一致性）。这些工具制作数据文件的原始文件系统级副本，以及崩溃恢复所需的日志，以处理由并发更改引起的一致性问题。在这里，我们遇到了I/O原子性的另一个含义：从可能并发写入的文件中读取。第一个问题是，当存在重叠的并发写入时，Linux和Windows上的文件系统（但不是ZFS，或FreeBSD上的任何文件系统，因为使用了范围锁）可以向读者显示随机选择的前位和后位。此外，I/O目前是以一种不适当对齐的方式进行的，因此即使在ZFS上，也可能复制被破坏的页面。为了防止这种情况，需要使用full_page_writes行为。这个问题最终应该在  PostgreSQL 中得到解决，方法是通过适当的对齐和互锁复制原始数据文件。请注意，如果采取了某些预防措施（主要是快照必须原子化地捕获日志和所有数据文件），可以使用ZFS快照而不是 pg_basebackup，从而减少克隆或备份一个非常繁忙的系统时的影响。

## 恢复
我们已经看到 **full_page_writes=off** 如何提高写事务的性能，而 ZFS 使其变得安全。不幸的是，复制和故障恢复也可能带来负面的性能影响。这两个活动都执行恢复，意味着它们会回放日志。尽管全页镜像在编写时令人讨厌，但在恢复时回放时，它们起到了优化的作用。我们不需要执行可能会阻止恢复的串行处理循环的随机同步读取，而是在我们良好的顺序日志中已经有了要修改的页面内容，然后将其缓存。

PostgreSQL 15包含了这个问题的部分解决方案：它在日志中查找即将被读取的页面，并执行 **POSIX_FADV_WILLNEED** 建议，以生成可配置的 I/O 并发度（一种穷人的异步I/O）。在撰写本文时，FreeBSD 忽略了这一建议，但未来版本的 OpenZFS 有望将其连接到 FreeBSD 的 VFS（OpenZFS拉取请求#13958）。最终，这应该被一个真正的异步I/O子系统所取代，该子系统目前正在开发中，并被提议用于未来版本的 PostgreSQL。

一个小组在 illumos 操作系统的ZFS上大规模使用 PostgreSQL，研究了 **full_page_writes=off** 对恢复 I/O 暂停的影响。他们开发了一种名为 **pg_prefaulter** 的工具作为变通方法。他们发现，由于可预测的I/O暂停，他们的流式复制副本无法跟上主服务器的速度。由于 PostgreSQL 的大多数大规模用户甚至没有设置 **full_page_writes=off** 的选项，因此它们可能是唯一能够看到这种效果的。如果遇到这个问题，**pg_prefaulter** 可能是一个解决方案，直到内置预取可用。

## 展望未来
在未来的 PostgreSQL 版本中，区块大小对齐可能会成为一个更大的话题，有望包括提议的直接 I/O 支持，目前仅以原型形式存在。这与 OpenZFS（pull request #10018）的直接 I/O 支持的发展不谋而合，这可能需要块大小的一致才能有效地工作（目前的原型恢复到 ARC，否则；一些其他的文件系统只是拒绝非对齐的直接 I/O ）。另一个对数据库非常有用的 OpenZFS 功能是块克隆（pull request#13392），以及 FreeBSD 的新系统接口，PostgreSQL 应该能够使用它来快速克隆数据库和数据库对象，其粒度比整个数据集更细。

---
**THOMAS MUNRO** 是一名为 Microsoft Azure 工作的开源数据库黑客，他通常登录到FreeBSD盒子中。