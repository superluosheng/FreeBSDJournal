# ZFS的Atomic I/O和PostgreSQL

# 虚拟实验室BSD编程研讨会

# ZFS简介

# WIP/CFT:数据包批处理

## ZFS的Atomic I/O和PostgreSQL (By Thomas Munro)

PostgreSQL 是一个实施 SQL 标准的关系数据库管理系统，具有类似BSD的许可证。SQL 早期的原型 POSTGRES 于80年代中期在伯克利大学开始。它在FreeBSD上很流行，在那里它通常被部署在ZFS存储上。

许多关于 PostgreSQL 在 ZFS 上的文章建议改变 ZFS 的 recordsize 设置和 PostgreSQL 的 full_page_writes 设置。后者的设置对性能和崩溃安全的真正影响并不经常被解释，也许是因为在大多数流行的文件系统上调整它通常是不安全的。在这篇文章中，围绕块的大小讨论之后我总结了这一神秘机制背后的逻辑和权衡。 

块 几乎所有 PostgreSQL 的磁盘I/O 都是在 8KB 块或页面上对齐的。重新编译它以使用不同的大小，但很少有人这样做。这个大小可能最初是为了匹配 UFS 的历史默认块大小（不过请注意 FreeBSD 的 UFS 现在默认为32KB）。ZFS 使用术语 "记录大小"，并默认为128KB。与其他文件系统不同，ZFS 允许在任何时候轻松改变记录大小，并为每个数据集单独配置。

如果数据是随机访问，那么在理论上，其大小最好与PostgreSQL的 8KB 的块相匹配。否则，随机I/O可能会受到两种影响。

- I/O放大，因为对 8KB 块的每一次读或写都会传输额外的邻近的数据

- 先读后写,当存储块目前不在操作系统的缓存中而一个 8KB 的块必须被写入，所以必须先读取相邻的数据。

如果数据大多数按顺序访问，或者很少访问，尤其是如果使用较大记录的 ZFS 压缩收益超过了对 I/O 带宽和延迟的担忧，那么这可能是一个好主意。

一些来源提出了16KB、32KB或 128KB 的记录大小的全面建推荐，作为在没有太多写入放大或延迟的情况下实现更好压缩的临界点。在这里，我未必有一个答案，而是要说明发生了什么。

有些应用对不同种类的数据有混合的要求。表空间可以用来在不同的ZFS数据集中存储不同的表，具有不同的记录大小、压缩或物理介质。也有可能对一个表进行分区，例如旧的数据在一个表空间，当前的活动数据在另一个表空间。

CREATE TABLESPACE compressed_tablespace
LOCATION /tank/pgdata/compressed_tablespace;
ALTER TABLE t
SET TABLESPACE compressed_tablespace;

据报道，小的ZFS记录大小的一个问题是碎片化。一个收到
频繁的随机更新的表可能最终会出现散落在各处的块，而我们
我们希望它们在物理上被集中起来，以获得良好的连续读取性能。一个简单的方法
要求PostgreSQL重写保存表及其索引的文件，以便在ZFS级别上对其进行碎片整理。
一个简单的方法是要求PostgreSQL重写存放表及其索引的文件，以便在ZFS级别上对它们进行碎片整理，这就是发布VACUUM FULL table_name或CLUSTER
table_name，如果你准备在重写期间将查询锁定在该表之外。
重写一个表也允许新的记录大小生效，如果它已经在数据集级别上被改变的话。
数据集层面上的改变，重写表也允许新的记录大小生效。


小的 ZFS 记录大小报告的一个问题是碎片。一个频繁接收随机更新的表最终可能会出现分散在各处的块，我们更希望它们在物理上被集中起来，以获得良好的顺序读取性能。如果您准备在重写期间将查询锁定在表之外，那么要求PostgreSQL重写包含表及其索引的文件以便在ZFS级别对其进行碎片整理的一种简单方法是发出 `VACUUM FULL table_name` 或 `CLUSTER table_name`。如果在数据集级别更改了新的记录大小，则重写表也可以使其生效。